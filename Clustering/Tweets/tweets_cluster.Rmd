---
title: "ANLY501_HW_MOD3_Tweets"
author: "Leyao Li"
date: "10/7/2020"
output: html_document
---

```{r}
library(wordcloud)

library(tm)

##library("Snowball")
##set working directory
## ONCE: install.packages("slam")
library(slam)
library(quanteda)
## ONCE: install.packages("quanteda")
## Note - this includes SnowballC
library(SnowballC)
library(arules)
##ONCE: install.packages('proxy')
library(proxy)

df <- read.csv('/Users/lingfengcao/Leyao/ANLY501/HW MOD03/tweets_R/tweets_labeled_clean.csv')

# only keep the clean_tweet column from the dataframe
df = df[c(10)]

# further clean out emoticons and abnormal words
df$clean_tweet <- sapply(df$clean_tweet,function(row) iconv(row, "latin1", "ASCII", sub=""))

corpus = tm::Corpus(tm::VectorSource(df$clean_tweet))

# Building the feature matrices
tdm <- tm::DocumentTermMatrix(corpus)
tdm.tfidf <- tm::weightTfIdf(tdm)

# remove a lot of features since R is not 
# good with high dimensional matrix
tdm.tfidf <- tm::removeSparseTerms(tdm.tfidf, 0.95)

tfidf.matrix <- as.matrix(tdm.tfidf)





```

Use Elbow, Silhouette and Gap Stat to determine optimal number of clusters

```{r}
library(factoextra)

# run silhouette method and the optimal number of clusters is 10
fviz_nbclust(tfidf.matrix, kmeans, method = "silhouette")

# run elbow method, but result does not show
# monotonically decreasing pattern and therefore
# would not be useful for determing optimal k
fviz_nbclust(tfidf.matrix, kmeans, method = "wss")

# run gap stats method and the result did not converge within 10 iterations
fviz_nbclust(tfidf.matrix, kmeans, method = "gap_stat")
```

K means cluster with k = 10 and visualize

```{r}
clustering.kmeans_10 <- kmeans(tfidf.matrix, 10)
# plot clustering
fviz_cluster(clustering.kmeans_10, data=tfidf.matrix,
             palette = 'rainbow', 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw(),
             title = 'cluster with k=10'
             )
```
K means cluster with k = 4  and visualize
```{r}
clustering.kmeans_4 <- kmeans(tfidf.matrix, 4)
# plot clustering
fviz_cluster(clustering.kmeans_4, data=tfidf.matrix,
             palette ='rainbow', 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw(),
             title = 'cluster with k=4'
             )
```
hierarchical cluster with 3 different distance matrices
```{r}


# Euclidean distance matrix 
d_euc <- dist(tfidf.matrix, method = "euclidean")

# cosine distance matrix
d_cos = proxy::dist(tfidf.matrix, method = "cosine")
# d_cos <-  1 - crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
# # remove all rows with non-finite values
# d_cos[!rowSums(!is.finite(d_cos)),]
# # replace all non-finite values with 0
# d_cos[!is.finite(d_cos)] <- 0

# Jaccard distance matrix
d_jac <- dist(tfidf.matrix, method = "Jaccard")

# Hierarchical clustering using Ward Linkage
hc_euc <- hclust(d_euc, method = "ward.D" )
hc_cos <- hclust(d_cos, method = "single" )
hc_jac <- hclust(d_jac, method = "ward.D" )

# Plot the obtained dendrogram of 3 different distance matrices used
# euclidean
plot(hc_euc, cex = 0.6, hang = -1, main='Hierarchical cluster with Euclidean distance')

# cosine
plot(hc_cos, cex = 0.6, hang = -1, main='Hierarchical cluster with Cosine similarity')

# jaccard
plot(hc_jac, cex = 0.6, hang = -1, main='Hierarchical cluster with Jaccard distance')

```

density based clustering
```{r}
library("fpc")
library('dbscan')
# determine optimal eps value
dbscan::kNNdistplot(tfidf.matrix, k =  10)
abline(h = 0.15, lty = 2)
# it seems like optimal eps value would be around 100

# compute DBSCAN using fpc package
db <- fpc::dbscan(tfidf.matrix, eps =0.2, MinPts = 10)

# plot 
fviz_cluster(db, tfidf.matrix, ellipse = FALSE, title='dbscan plot for eps=0.2')
print(db)
```